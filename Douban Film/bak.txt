import scrapy
import json

class doubanSpider(scrapy.Spider):
    name = "douban"
    allowed_domains = ["douban.com"]
    
    def start_requests(self):
        urls = []
        for i in range(1, 14):
            urls.append('https://movie.douban.com/j/search_subjects?type=movie&tag=%E7%83%AD%E9%97%A8&sort=recommend&page_limit=20&page_start=' + str(i * 20))
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}
        for url in urls:
            yield scrapy.Request(url = url, headers = headers, method = 'GET', callback = self.parse)

    def parse(self, response):
        tmp = response.body.decode('utf-8')
        table = json.load(tmp)
        for item in table['subject']:
            filename = item['title'] + item['rate'] + 'åˆ†.jpg'
            urllib.request.urlretrieve(item['cover'], filename)